{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Compute performance metrics for the given data 5_a.csv\n",
    "\n",
    "  Note 1: in this data you can see number of positive points >> number of negatives points\n",
    "\n",
    "  Note 3: you need to derive the class labels from given score\n",
    "\n",
    "  $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
    "\n",
    "\n",
    " - Compute Confusion Matrix\n",
    "\n",
    " - Compute F1 Score\n",
    "\n",
    " - Compute AUC Score, you need to compute different thresholds and for each threshold compute tpr,fpr and then use\n",
    "\n",
    " numpy.trapz(tpr_array, fpr_array)\n",
    "\n",
    " https://stackoverflow.com/q/53603376/4084039\n",
    "\n",
    " https://stackoverflow.com/a/39678975/4084039\n",
    "\n",
    " Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)\n",
    "\n",
    "- Compute Accuracy Score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10100, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": "     y     proba\n0  1.0  0.637387\n1  1.0  0.635165\n2  1.0  0.766586\n3  1.0  0.724564\n4  1.0  0.889199",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>y</th>\n      <th>proba</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.637387</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.635165</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.766586</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.724564</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.889199</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_5_a = pd.read_csv('./Instructions/5_a.csv')\n",
    "print(df_5_a.shape)\n",
    "df_5_a.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# df_5_a_small = pd.read_csv('Instructions/5_a.csv', nrows=10 )\n",
    "# df_5_a_small.head(10)\n",
    "# print(df_5_a_small.to_numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "data": {
      "text/plain": "     y     proba  y_predicted\n0  1.0  0.637387          1.0\n1  1.0  0.635165          1.0\n2  1.0  0.766586          1.0\n3  1.0  0.724564          1.0\n4  1.0  0.889199          1.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>y</th>\n      <th>proba</th>\n      <th>y_predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.637387</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>0.635165</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.766586</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>0.724564</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.0</td>\n      <td>0.889199</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_5_a['y_predicted'] = np.where(df_5_a['proba'] >= 0.5, float(1), float(0))\n",
    "df_5_a.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [],
   "source": [
    "# Checking to see if there's any 'proba' less than or equal to 0.5\n",
    "# And there is none. So all y_predicted will be classified as 1\n",
    "# df = df_5_a.loc[df_5_a['proba'] <= 0.5 ]\n",
    "# df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual_y_train_arr  [1. 1. 1. ... 1. 1. 1.]\n",
      "predicted_y_arr  [1. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# print(df_5_a.to_numpy())\n",
    "actual_y_train_arr = df_5_a.iloc[:, 0].values\n",
    "print('actual_y_train_arr ', actual_y_train_arr)\n",
    "predicted_y_arr = df_5_a.iloc[:, 2].values\n",
    "print('predicted_y_arr ', predicted_y_arr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10000.   100.]\n",
      " [    0.     0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_confusion_matrix(true_y_classes_array, predicted_y_classes_array):\n",
    "\n",
    "  unique_classes = np.unique(true_y_classes_array)\n",
    "  # For a binary class the above will give me [0 1] numpy array\n",
    "  # so top-left of confusion matrix will start from 0 i.e. 'True Negative'\n",
    "\n",
    "  # But the challenge here asks that the top left will be 'True Positive'\n",
    "  # Hence I need to reverse the above numpy array\n",
    "  unique_classes = unique_classes[::-1]\n",
    "  # print('reversed unique', unique_classes) # will convert the above array to [1 0]\n",
    "\n",
    "  # initialize a matrix with zero values that will be the final confusion matrix\n",
    "  # For the binary class-label dataset, this confusion matrix will be a 2*2 square matrix\n",
    "  confusion_matrix = np.zeros((len(unique_classes), len(unique_classes)))\n",
    "\n",
    "  for i in range(len(unique_classes)):\n",
    "    for j in range(len(unique_classes)):\n",
    "      confusion_matrix[i, j] = np.sum((true_y_classes_array == unique_classes[j]) & (predicted_y_classes_array == unique_classes[i]))\n",
    "\n",
    "  return confusion_matrix\n",
    "\n",
    "confusion_matrix_5_a = get_confusion_matrix(actual_y_train_arr, predicted_y_arr)\n",
    "print(confusion_matrix_5_a)\n",
    "\n",
    "true_negative, false_positive, false_negative, true_positive = int(confusion_matrix_5_a[1][1]), int(confusion_matrix_5_a[0][1]), int(confusion_matrix_5_a[1][0]), int(confusion_matrix_5_a[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Explanations and notes on above Confusion matrix function\n",
    "\n",
    "![img](https://i.imgur.com/1A3Izpg.png)\n",
    "\n",
    "#### Note `unique_classes[0]` is 1 and `unique_classes[1]` = 0\n",
    "\n",
    "### For first row of my final confusion_matrix\n",
    "\n",
    "`confusion_matrix[0,0]` => i.e. i, j = 0, 0 => will have the Total 'True' count (i.e. `np.sum()`) of following conditions\n",
    "\n",
    "`(true_y_classes_array == unique_classes[0]) & (predicted_y_classes_array == unique_classes[0])`\n",
    "\n",
    "Similarly for `confusion_matrix[0, 1]` => i.e. i, j = 0, 1 => will have the Total 'True' count (i.e. `np.sum()`)  of following conditions\n",
    "\n",
    "`(true_y_classes_array == unique_classes[1]) & (predicted_y_classes_array == unique_classes[0])`\n",
    "\n",
    "---\n",
    "\n",
    "### Now second row\n",
    "\n",
    "And for second row of my final confusion_matrix\n",
    "\n",
    "`confusion_matrix[1,0]`  => i.e. i, j = 1, 0 => will have the Total 'True' count (i.e. `np.sum()`)  of following conditions\n",
    "\n",
    "`(true_y_classes_array == unique_classes[0]) & (predicted_y_classes_array == unique_classes[1])`\n",
    "\n",
    "Similarly for `confusion_matrix[1, 1]`  => i.e. i, j = 1, 1  => will have the Total 'True' count (i.e. `np.sum()`) of following conditions\n",
    "\n",
    "\n",
    "`(true_y_classes_array == unique_classes[1]) & (predicted_y_classes_array == unique_classes[1])`"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# To check that the total num of elements of the original dataframe matches\n",
    "# with the counts captured in the confusion matrix\n",
    "# sum-all-the-elements-of-the confusion_matrix_5_a\n",
    "sum_all_elements_of_confusion_matrix = np.concatenate(confusion_matrix_5_a).sum()\n",
    "print(sum_all_elements_of_confusion_matrix == df_5_a.shape[0] )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    0   100]\n",
      " [    0 10000]]\n"
     ]
    }
   ],
   "source": [
    "# Testing my custom confusion_matrix result with scikit-learn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sklearn_confustion_matrix = confusion_matrix(actual_y_train_arr, predicted_y_arr)\n",
    "print(sklearn_confustion_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 0 10000\n",
      "0 100 0 10000\n"
     ]
    }
   ],
   "source": [
    "# Verifying individual elements of the Confusion matrix from my custom result with scikit-learn\n",
    "tn, fp, fn, tp = confusion_matrix(actual_y_train_arr, predicted_y_arr).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "print(true_negative, false_positive, false_negative, true_positive)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### From above we can see the values of the confution Matrix matches between scikit-learn and our custom-implementation\n",
    "\n",
    "---\n",
    "\n",
    "## F1 Score\n",
    "\n",
    "![img](https://i.imgur.com/ZPntYB0.jpg)\n",
    "\n",
    "![Imgur](https://imgur.com/qy5Fesd.jpg)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.9950248756218906, 10100.0)\n"
     ]
    }
   ],
   "source": [
    "# the below function will work only for\n",
    "# binary confusion matrix\n",
    "def get_f1_accuracy(binary_conf_matrix):\n",
    "    true_negative  = binary_conf_matrix[1][1]    \n",
    "    false_positive = binary_conf_matrix[0][1]\n",
    "    false_negative = binary_conf_matrix[1][0]\n",
    "    true_positive = binary_conf_matrix[0][0]\n",
    "\n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "    recall = true_positive/ (true_positive + false_negative)\n",
    "    \n",
    "    f1_score = (2 * (precision * recall)) / (precision + recall )\n",
    "    \n",
    "    sum_all_elements_of_confusion_matrix = np.concatenate(binary_conf_matrix).sum()\n",
    "    \n",
    "    accuracy = (true_positive + true_negative)/sum_all_elements_of_confusion_matrix\n",
    "    \n",
    "    return f1_score, sum_all_elements_of_confusion_matrix\n",
    "\n",
    "\n",
    "print(get_f1_accuracy(confusion_matrix_5_a))\n",
    "    \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now verifying the above result with that of sk-learn\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}